{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e9d58d-3fa1-416c-bbf5-355bbec13c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URLs added to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = '10_anime.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Define a function to scrape the image URL from MyAnimeList\n",
    "def get_anime_image_url(anime_name):\n",
    "    search_url = f\"https://myanimelist.net/search/all?q={anime_name.replace(' ', '%20')}&cat=all\"\n",
    "    response = requests.get(search_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        result = soup.find('a', {'class': 'hoverinfo_trigger'})\n",
    "        if result:\n",
    "            anime_page_url = result['href']\n",
    "            anime_response = requests.get(anime_page_url)\n",
    "            if anime_response.status_code == 200:\n",
    "                anime_soup = BeautifulSoup(anime_response.text, 'html.parser')\n",
    "                image_tag = anime_soup.find('img', {'itemprop': 'image'})\n",
    "                if image_tag:\n",
    "                    return image_tag['data-src'] if 'data-src' in image_tag.attrs else image_tag['src']\n",
    "    return None\n",
    "\n",
    "# Add a new column for image URLs\n",
    "df['image_url'] = df['name'].apply(get_anime_image_url)\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv('images.csv', index=False)\n",
    "\n",
    "print(\"Image URLs added to the CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5712f82a-c067-4f4f-b602-b4de03c68d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URLs added to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import time\n",
    "from aiohttp import ClientTimeout\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = '10_anime.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Exponential backoff logic and error handling for fetching the image URL\n",
    "async def get_anime_image_url(session, anime_name, retries=5, base_delay=1):\n",
    "    search_url = f\"https://myanimelist.net/search/all?q={anime_name.replace(' ', '%20')}&cat=all\"\n",
    "    timeout = ClientTimeout(total=15)  # Set a timeout for requests\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            async with session.get(search_url, timeout=timeout) as response:\n",
    "                if response.status == 200:\n",
    "                    html = await response.text()\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    result = soup.find('a', {'class': 'hoverinfo_trigger'})\n",
    "                    if result:\n",
    "                        anime_page_url = result['href']\n",
    "                        async with session.get(anime_page_url, timeout=timeout) as anime_response:\n",
    "                            if anime_response.status == 200:\n",
    "                                anime_html = await anime_response.text()\n",
    "                                anime_soup = BeautifulSoup(anime_html, 'html.parser')\n",
    "                                image_tag = anime_soup.find('img', {'itemprop': 'image'})\n",
    "                                if image_tag:\n",
    "                                    return image_tag['data-src'] if 'data-src' in image_tag.attrs else image_tag['src']\n",
    "        except (aiohttp.ClientOSError, asyncio.TimeoutError, aiohttp.ClientResponseError) as e:\n",
    "            delay = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "            print(f\"Error fetching {anime_name}: {e}. Retrying in {delay} seconds...\")\n",
    "            await asyncio.sleep(delay)  # Exponential delay before retrying\n",
    "    return None  # Return None if all retries fail\n",
    "\n",
    "# Main asynchronous function to fetch image URLs with rate limiting\n",
    "async def fetch_all_image_urls(anime_names, delay_between_requests=1):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for anime_name in anime_names:\n",
    "            tasks.append(get_anime_image_url(session, anime_name))\n",
    "            await asyncio.sleep(delay_between_requests)  # Fixed delay between requests\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "# Get all image URLs asynchronously with rate limiting\n",
    "anime_names = df['name'].tolist()\n",
    "image_urls = asyncio.run(fetch_all_image_urls(anime_names))\n",
    "  \n",
    "# Add the image URLs to the DataFrame\n",
    "df['image_url'] = image_urls\n",
    "\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv('fetch_with_images.csv', index=False)\n",
    "\n",
    "print(\"Image URLs added to the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c21cd3d-e16d-45fe-b9c4-6b80d5f5756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching Bakabon Osomatsu no Karee wo Tazunete Sansenri: . Retrying in 10 seconds...\n",
      "Error fetching Baku Tech! Bakugan Gachi: Tokubetsu-hen: . Retrying in 10 seconds...\n",
      "Error fetching Balgwanghaneun Hyeondaesa: . Retrying in 10 seconds...\n",
      "Error fetching Be-Bop Kaizokuban: . Retrying in 10 seconds...\n",
      "Error fetching Bikkuriman: Moen Zone no Himitsu: . Retrying in 10 seconds...\n",
      "Error fetching Bouken Korobokkuru: . Retrying in 10 seconds...\n",
      "Error fetching Bouken Gabotenjima: . Retrying in 10 seconds...\n",
      "Error fetching Bikkuriman: Daiichiji Seima Taisen: . Retrying in 10 seconds...\n",
      "Error fetching Bosco no Mori no Nakama-tachi: . Retrying in 10 seconds...\n",
      "Error fetching Boo Boo Boy: . Retrying in 10 seconds...\n",
      "Error fetching Bazar d√© Gozarre: . Retrying in 10 seconds...\n",
      "Error fetching Bikkuriman 2000: . Retrying in 10 seconds...\n",
      "Error fetching Bonobono: Kumomo no Ki no Koto: . Retrying in 10 seconds...\n",
      "Error fetching Bonobono (TV) Specials: . Retrying in 10 seconds...\n",
      "Error fetching Bonobono: . Retrying in 10 seconds...\n",
      "Error fetching Bokutachi no Peace River: . Retrying in 10 seconds...\n",
      "Error fetching Bakusou Circuit Roman Twin: . Retrying in 10 seconds...\n",
      "Error fetching Battle Spirits Shinnen Special: . Retrying in 10 seconds...\n",
      "Error fetching Bikini Warriors OVA: . Retrying in 10 seconds...\n",
      "Error fetching Bokura no Saibanin Monogatari: . Retrying in 10 seconds...\n",
      "Error fetching Bokura Mangaka: Tokiwasou Monogatari: . Retrying in 10 seconds...\n",
      "Error fetching Big X Episode 0: . Retrying in 10 seconds...\n",
      "Error fetching Bokura Machi Bouzu!: . Retrying in 10 seconds...\n",
      "Error fetching Boku wa Sugu ni Nigetanda: Higashi Nihon Daishinsai kara Mananda Koto: . Retrying in 10 seconds...\n",
      "Error fetching Batsu &amp; Terry: . Retrying in 10 seconds...\n",
      "Error fetching Big X: . Retrying in 10 seconds...\n",
      "Error fetching Boku wa Ou-sama (TV) Special: . Retrying in 10 seconds...\n",
      "Error fetching Boku wa Ou-sama (TV): . Retrying in 10 seconds...\n",
      "Error fetching Big Mouth Do Do: . Retrying in 10 seconds...\n",
      "Error fetching Boku wa Ou-sama: . Retrying in 10 seconds...\n",
      "Error fetching Cello Hiki no Gauche (OVA): . Retrying in 10 seconds...\n",
      "Error fetching Cello Hiki no Gauche: . Retrying in 10 seconds...\n",
      "Error fetching Boku wa Koko de Ikiteiku: . Retrying in 10 seconds...\n",
      "Error fetching Carino Coni: . Retrying in 10 seconds...\n",
      "Error fetching Baki: . Retrying in 10 seconds...\n",
      "Error fetching Bakujuu Gasshin Ziguru Hazeru: . Retrying in 10 seconds...\n",
      "Error fetching Boku wa Kimi wo Warawanai: . Retrying in 10 seconds...\n",
      "Error fetching Captain the Movie: . Retrying in 10 seconds...\n",
      "Error fetching Captain (TV): . Retrying in 10 seconds...\n",
      "Error fetching Boku to Gaku: Ano Natsu no Monogatari: . Retrying in 10 seconds...\n",
      "Error fetching Boku no Son Gokuu: . Retrying in 10 seconds...\n",
      "Error fetching Cakes: . Retrying in 10 seconds...\n",
      "Error fetching Boku no Diet Daisakusen: . Retrying in 10 seconds...\n",
      "Error fetching Byeolnala Samchongsa: . Retrying in 10 seconds...\n",
      "Error fetching Butazuka: . Retrying in 10 seconds...\n",
      "Error fetching Bary-san no Imabari-ben Kouza: . Retrying in 10 seconds...\n",
      "Error fetching Bero-dashi Chonma: . Retrying in 10 seconds...\n",
      "Error fetching Burutabu-chan: . Retrying in 10 seconds...\n",
      "Error fetching Burning Village: . Retrying in 10 seconds...\n",
      "Error fetching Boku no Aozora: . Retrying in 10 seconds...\n",
      "Error fetching Burning Blood: . Retrying in 10 seconds...\n",
      "Error fetching Beompeoking Jaepeo: . Retrying in 10 seconds...\n",
      "Error fetching Boku datte, Kirei ni Shitainda: . Retrying in 10 seconds...\n",
      "Error fetching Bunna yo Ki kara Orite Koi: . Retrying in 10 seconds...\n",
      "Error fetching Bungaku Shounen no Yuuutsu: . Retrying in 10 seconds...\n",
      "Error fetching Bogeul Bogeul Bomulseon: . Retrying in 10 seconds...\n",
      "Error fetching Bunbuku Chagama (1958): . Retrying in 10 seconds...\n",
      "Error fetching Bunbuku Chagama: . Retrying in 10 seconds...\n",
      "Error fetching Bakuhatsu Gorou: . Retrying in 10 seconds...\n",
      "Error fetching Barnacle Lou: . Retrying in 10 seconds...\n",
      "Error fetching Bocchan: . Retrying in 10 seconds...\n",
      "Error fetching Bulsajo Robot Phoenix King: . Retrying in 10 seconds...\n",
      "Error fetching Bloody Bunny: . Retrying in 10 seconds...\n",
      "Error fetching Bucket no Ana: . Retrying in 10 seconds...\n",
      "Error fetching Believe in It: . Retrying in 10 seconds...\n",
      "Error fetching Blend: . Retrying in 10 seconds...\n",
      "Error fetching Black Clover: . Retrying in 10 seconds...\n",
      "Error fetching Bubaga: . Retrying in 10 seconds...\n",
      "Error fetching Break-Age: . Retrying in 10 seconds...\n",
      "Error fetching Ball yo Doko e Yuku: . Retrying in 10 seconds...\n",
      "Error fetching Brave Fire S0.9: . Retrying in 10 seconds...\n",
      "Error fetching Boyfriend: . Retrying in 10 seconds...\n",
      "Error fetching Biriken Nandemo Shoukai: . Retrying in 10 seconds...\n",
      "Error fetching Box: . Retrying in 10 seconds...\n",
      "Error fetching Bousou Sengokushi: . Retrying in 10 seconds...\n",
      "Error fetching Beanuts: . Retrying in 10 seconds...\n",
      "Error fetching Biriken: . Retrying in 10 seconds...\n",
      "Error fetching Bouningen Weekend: . Retrying in 10 seconds...\n",
      "Error fetching Bouken-tachi Gamba to Nanbiki no Nakama: . Retrying in 10 seconds...\n",
      "Error fetching Bouken Yuuki Pluster World: . Retrying in 10 seconds...\n",
      "Error fetching Bouken Shounen Shadar: . Retrying in 10 seconds...\n",
      "Error fetching Bucket de Gohan: . Retrying in 10 seconds...\n",
      "Error fetching Captain: . Retrying in 10 seconds...\n",
      "Error fetching Boku datte, Kirei ni Shitainda: . Retrying in 20 seconds...\n",
      "Error fetching Bunna yo Ki kara Orite Koi: . Retrying in 20 seconds...\n",
      "Error fetching Bunbuku Chagama: . Retrying in 20 seconds...\n",
      "Error fetching Bloody Bunny: . Retrying in 20 seconds...\n",
      "Error fetching Batsu &amp; Terry: . Retrying in 20 seconds...\n",
      "Error fetching Boku wa Ou-sama (TV): . Retrying in 20 seconds...\n",
      "Error fetching Believe in It: . Retrying in 20 seconds...\n",
      "Error fetching Bulsajo Robot Phoenix King: . Retrying in 20 seconds...\n",
      "Error fetching Black Clover: . Retrying in 20 seconds...\n",
      "Error fetching Blend: . Retrying in 20 seconds...\n",
      "Error fetching Bocchan: . Retrying in 20 seconds...\n",
      "Error fetching Boku wa Ou-sama (TV) Special: . Retrying in 20 seconds...\n",
      "Error fetching Biriken: . Retrying in 20 seconds...\n",
      "Error fetching Box: . Retrying in 20 seconds...\n",
      "Error fetching Boo Boo Boy: . Retrying in 20 seconds...\n",
      "Error fetching Bouken Gabotenjima: . Retrying in 20 seconds...\n",
      "Error fetching Bikkuriman 2000: . Retrying in 20 seconds...\n",
      "Error fetching Bouken Korobokkuru: . Retrying in 20 seconds...\n",
      "Error fetching Bokutachi no Peace River: . Retrying in 20 seconds...\n",
      "Error fetching Bikini Warriors OVA: . Retrying in 20 seconds...\n",
      "Error fetching Bikkuriman: Daiichiji Seima Taisen: . Retrying in 20 seconds...\n",
      "Error fetching Bonobono: Kumomo no Ki no Koto: . Retrying in 20 seconds...\n",
      "Error fetching Bakujuu Gasshin Ziguru Hazeru: . Retrying in 20 seconds...\n",
      "Error fetching Big X: . Retrying in 20 seconds...\n",
      "Error fetching Carino Coni: . Retrying in 20 seconds...\n",
      "Error fetching Boku wa Ou-sama: . Retrying in 20 seconds...\n",
      "Error fetching Cello Hiki no Gauche (OVA): . Retrying in 20 seconds...\n",
      "Error fetching Big Mouth Do Do: . Retrying in 20 seconds...\n",
      "Error fetching Baki: . Retrying in 20 seconds...\n",
      "Error fetching Boku to Gaku: Ano Natsu no Monogatari: . Retrying in 20 seconds...\n",
      "Error fetching Boku no Son Gokuu: . Retrying in 20 seconds...\n",
      "Error fetching Boku wa Kimi wo Warawanai: . Retrying in 20 seconds...\n",
      "Error fetching Big X Episode 0: . Retrying in 20 seconds...\n",
      "Error fetching Be-Bop Kaizokuban: . Retrying in 20 seconds...\n",
      "Error fetching Butazuka: . Retrying in 20 seconds...\n",
      "Error fetching Byeolnala Samchongsa: . Retrying in 20 seconds...\n",
      "Error fetching Baku Tech! Bakugan Gachi: Tokubetsu-hen: . Retrying in 20 seconds...\n",
      "Error fetching Boku no Diet Daisakusen: . Retrying in 20 seconds...\n",
      "Error fetching Cakes: . Retrying in 20 seconds...\n",
      "Error fetching Balgwanghaneun Hyeondaesa: . Retrying in 20 seconds...\n",
      "Error fetching Bakabon Osomatsu no Karee wo Tazunete Sansenri: . Retrying in 20 seconds...\n",
      "Error fetching Bubaga: . Retrying in 20 seconds...\n",
      "Error fetching Cello Hiki no Gauche: . Retrying in 20 seconds...\n",
      "Error fetching Bucket no Ana: . Retrying in 20 seconds...\n",
      "Error fetching Beanuts: . Retrying in 20 seconds...\n",
      "Error fetching Burning Village: . Retrying in 20 seconds...\n",
      "Error fetching Barnacle Lou: . Retrying in 20 seconds...\n",
      "Error fetching Bunbuku Chagama (1958): . Retrying in 20 seconds...\n",
      "Error fetching Burning Blood: . Retrying in 20 seconds...\n",
      "Error fetching Bouningen Weekend: . Retrying in 20 seconds...\n",
      "Error fetching Bero-dashi Chonma: . Retrying in 20 seconds...\n",
      "Error fetching Bikkuriman: Moen Zone no Himitsu: . Retrying in 20 seconds...\n",
      "Error fetching Boku no Aozora: . Retrying in 20 seconds...\n",
      "Error fetching Bakusou Circuit Roman Twin: . Retrying in 20 seconds...\n",
      "Error fetching Bouken Yuuki Pluster World: . Retrying in 20 seconds...\n",
      "Error fetching Bokura Mangaka: Tokiwasou Monogatari: . Retrying in 20 seconds...\n",
      "Error fetching Bouken-tachi Gamba to Nanbiki no Nakama: . Retrying in 20 seconds...\n",
      "Error fetching Battle Spirits Shinnen Special: . Retrying in 20 seconds...\n",
      "Error fetching Bary-san no Imabari-ben Kouza: . Retrying in 20 seconds...\n",
      "Error fetching Burutabu-chan: . Retrying in 20 seconds...\n",
      "Error fetching Captain the Movie: . Retrying in 20 seconds...\n",
      "Error fetching Boku wa Ou-sama (TV) Special: . Retrying in 40 seconds...\n",
      "Error fetching Carino Coni: . Retrying in 40 seconds...\n",
      "Error fetching Boku no Son Gokuu: . Retrying in 40 seconds...\n",
      "Error fetching Boku to Gaku: Ano Natsu no Monogatari: . Retrying in 40 seconds...\n",
      "Error fetching Bikkuriman: Moen Zone no Himitsu: . Retrying in 40 seconds...\n",
      "Error fetching Butazuka: . Retrying in 40 seconds...\n",
      "Error fetching Cakes: . Retrying in 40 seconds...\n",
      "Error fetching Bokutachi no Peace River: . Retrying in 40 seconds...\n",
      "Error fetching Bubaga: . Retrying in 40 seconds...\n",
      "Error fetching Bakabon Osomatsu no Karee wo Tazunete Sansenri: . Retrying in 40 seconds...\n",
      "Error fetching Beanuts: . Retrying in 40 seconds...\n",
      "Error fetching Biriken: . Retrying in 40 seconds...\n",
      "Error fetching Bouken Gabotenjima: . Retrying in 40 seconds...\n",
      "Error fetching Box: . Retrying in 40 seconds...\n",
      "Error fetching Bikkuriman 2000: . Retrying in 40 seconds...\n",
      "Error fetching Bloody Bunny: . Retrying in 40 seconds...\n",
      "Error fetching Boku wa Ou-sama (TV): . Retrying in 40 seconds...\n",
      "Error fetching Black Clover: . Retrying in 40 seconds...\n",
      "Error fetching Boku datte, Kirei ni Shitainda: . Retrying in 40 seconds...\n",
      "Error fetching Bunna yo Ki kara Orite Koi: . Retrying in 40 seconds...\n",
      "Error fetching Bocchan: . Retrying in 40 seconds...\n",
      "Error fetching Battle Spirits Shinnen Special: . Retrying in 40 seconds...\n",
      "Error fetching Burning Village: . Retrying in 40 seconds...\n",
      "Error fetching Boku wa Kimi wo Warawanai: . Retrying in 40 seconds...\n",
      "Error fetching Burutabu-chan: . Retrying in 40 seconds...\n",
      "Error fetching Bokura Mangaka: Tokiwasou Monogatari: . Retrying in 40 seconds...\n",
      "Error fetching Bunbuku Chagama: . Retrying in 40 seconds...\n",
      "Failed to retrieve search page for Bubaga: Status 405\n",
      "Failed to retrieve search page for Bouken Gabotenjima: Status 405\n",
      "Failed to retrieve search page for Battle Spirits Shinnen Special: Status 405\n",
      "Failed to retrieve search page for Beanuts: Status 405\n",
      "Failed to retrieve search page for Butazuka: Status 405\n",
      "Failed to retrieve search page for Boku datte, Kirei ni Shitainda: Status 405\n",
      "Failed to retrieve search page for Boku wa Ou-sama (TV): Status 405\n",
      "Failed to retrieve search page for Bokutachi no Peace River: Status 405\n",
      "Failed to retrieve search page for Carino Coni: Status 405\n",
      "Failed to retrieve search page for Bakabon Osomatsu no Karee wo Tazunete Sansenri: Status 405\n",
      "Failed to retrieve search page for Boku wa Ou-sama (TV) Special: Status 405\n",
      "Failed to retrieve search page for Bubaga: Status 405\n",
      "Failed to retrieve search page for Cakes: Status 405\n",
      "Failed to retrieve search page for Bouken Gabotenjima: Status 405\n",
      "Failed to retrieve search page for Beanuts: Status 405\n",
      "Failed to retrieve search page for Butazuka: Status 405\n",
      "Failed to retrieve search page for Boku datte, Kirei ni Shitainda: Status 405\n",
      "Failed to retrieve search page for Boku wa Ou-sama (TV): Status 405\n",
      "Failed to retrieve search page for Bokutachi no Peace River: Status 405\n",
      "Failed to retrieve search page for Bakabon Osomatsu no Karee wo Tazunete Sansenri: Status 405\n",
      "Failed to retrieve search page for Carino Coni: Status 405\n",
      "Failed to retrieve search page for Boku wa Ou-sama (TV) Special: Status 405\n",
      "Failed to retrieve search page for Battle Spirits Shinnen Special: Status 405\n",
      "Failed to retrieve search page for Bunbuku Chagama: Status 405\n",
      "Failed to retrieve search page for Bunbuku Chagama: Status 405\n",
      "Failed to retrieve search page for Cakes: Status 405\n",
      "Failed to retrieve search page for Black Clover: Status 405\n",
      "Failed to retrieve search page for Black Clover: Status 405\n",
      "Image URLs added to the CSV file in 391.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import time\n",
    "from aiohttp import ClientTimeout\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = '100_anime.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Exponential backoff logic and error handling for fetching the image URL\n",
    "async def get_anime_image_url(session, anime_name, retries=5, base_delay=10):\n",
    "    search_url = f\"https://myanimelist.net/search/all?q={anime_name.replace(' ', '%20')}&cat=all\"\n",
    "    timeout = ClientTimeout(total=30)  # Increased timeout for slower connections\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            async with session.get(search_url, timeout=timeout) as response:\n",
    "                if response.status == 200:\n",
    "                    html = await response.text()\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    result = soup.find('a', {'class': 'hoverinfo_trigger'})\n",
    "                    if result:\n",
    "                        anime_page_url = result['href']\n",
    "                        async with session.get(anime_page_url, timeout=timeout) as anime_response:\n",
    "                            if anime_response.status == 200:\n",
    "                                anime_html = await anime_response.text()\n",
    "                                anime_soup = BeautifulSoup(anime_html, 'html.parser')\n",
    "                                image_tag = anime_soup.find('img', {'itemprop': 'image'})\n",
    "                                if image_tag:\n",
    "                                    return image_tag['data-src'] if 'data-src' in image_tag.attrs else image_tag['src']\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve search page for {anime_name}: Status {response.status}\")\n",
    "        except (aiohttp.ClientOSError, asyncio.TimeoutError, aiohttp.ClientResponseError) as e:\n",
    "            delay = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "            print(f\"Error fetching {anime_name}: {e}. Retrying in {delay} seconds...\")\n",
    "            await asyncio.sleep(delay)  # Exponential delay before retrying\n",
    "    return None  # Return None if all retries fail\n",
    "\n",
    "# Main asynchronous function to fetch image URLs with rate limiting\n",
    "async def fetch_all_image_urls(anime_names, delay_between_requests=2):  # Increased delay to 2 seconds\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for anime_name in anime_names:\n",
    "            tasks.append(get_anime_image_url(session, anime_name))\n",
    "            await asyncio.sleep(delay_between_requests)  # Fixed delay between requests\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "# Get all image URLs asynchronously with rate limiting\n",
    "anime_names = df['name'].tolist()\n",
    "\n",
    "# Try to fetch the image URLs\n",
    "start_time = time.time()\n",
    "image_urls = asyncio.run(fetch_all_image_urls(anime_names))\n",
    "end_time = time.time()\n",
    "\n",
    "# Add the image URLs to the DataFrame\n",
    "df['image_url'] = image_urls\n",
    " \n",
    "# Save the updated CSV file\n",
    "df.to_csv('fetch_with_images.csv', index=False)\n",
    "\n",
    "print(f\"Image URLs added to the CSV file in {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe404c-8a09-4f4c-9d6a-d64008ab6f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9e24c-0f63-4c5d-b947-bc990900aff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
